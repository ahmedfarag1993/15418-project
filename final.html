<!DOCTYPE html>
<html lang="en">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1.0"/>
  <title>Parallelizing Bor&#367vka's Algorithm</title>

  <!-- CSS  -->
  <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">
  <link href="css/materialize.css" type="text/css" rel="stylesheet" media="screen,projection"/>
  <style>
    table, th, td {
      border: 1px solid black;
      border-collapse: collapse;
    }
  </style>
</head>
<body>
  <header>
    <nav class="indigo" role="navigation">
      <div class="nav-wrapper container"><a id="logo-container" href="#" class="brand-logo">15-418 Final Project</a>
        <ul class="right hide-on-med-and-down">
          <li><a href="index.html">Proposal</a></li>
          <li><a href="checkpoint.html">Check Point</a></li>
          <li><a href="#">Final Write-Up</a></li>
        </ul>
  
        <ul id="nav-mobile" class="side-nav">
          <li><a href="index.html">Proposal</a></li>
          <li><a href="checkpoint.html">Check Point</a></li>
          <li><a href="#">Final Write-Up</a></li>
        </ul>
        <a href="#" data-activates="nav-mobile" class="button-collapse"><i class="material-icons">menu</i></a>
      </div>
    </nav>
  </header>

  <main>
    <div class="container">
      <div class="section">
        <div class="row">
          <div class="col s12 m12">
            <h2>Parallelizing Bor&#367vka's Algorithm</h2>
            <h3>(Final Writeup)</h3>
            <p>By Kathleen Fuh (kfuh) and Shreya Vemuri (shreyav)</p> 
          </div>
        </div>
      </div>
    </div>

    <div class="container">
      <div class="section">
        <div class="row">
          <div class="col s12 m12">
            <h4>Summary</h4>
            <p>For our project, we wrote a sequential version of Bor&#367vka’s algorithm for finding minimum spanning trees in C++ and optimized its performance on a CPU using OpenMP and parallelizing techniques. In the process of parallelizing, we explored both edge and star contraction techniques for Bor&#367vka’s algorithm. We then analyzed the performance on the GHC machines with various numbers of threads.</p>
          </div>
        </div>
      </div>
    </div>
    
    <div class="container">
      <div class="section">
        <div class="row">
          <div class="col s12 m12">
            <h4>Background</h4>
            <p>A spanning tree of a connected, undirected graph <i>G</i> with vertex set <i>V</i> and edge set <i>E</i> is a connected subgraph of <i>G</i> that includes all vertices of <i>G</i> and exactly |<i>V</i>|-1 edges. When given a connected, weighted, undirected graph, the minimum spanning tree (MST) is a spanning tree with minimum total edge weight.</p>
            <p>The key property that drives many MST algorithms is the light edge property. This property states that for any cut of a connected, undirected, weighted graph <i>G</i>, the edge with minimum weight that crosses the cut must be in the MST.</p>
            <p>Bor&#367vka’s algorithm is a well-known parallel algorithm for finding MSTs. It makes use of the light edge property by observing that the minimum weight edge incident on any vertex <i>v</i> must be in the MST (the cut of the graph in this case partitions the graph into one set containing the single vertex <i>v</i> and a second set containing the rest of the graph). This observation introduces an axis of parallelism along vertices because edges in the MST can be selected in parallel by looking at each vertex. Using this idea, Bor&#367vka’s algorithm works as follows</p>
            <p>While there are still edges:</p>
            <ol>
              <li>Find the minimum weight edge incident on each vertex (these edges will form at least one connected component)</li>
              <li>Contract each connected component, creating a new super vertex for all vertices in the component</li>
              <li>Add the minimum weight edge between super vertices to the MST and remove all other redundant edges.</li>
            </ol>
            <p>There are two different techniques to approaching this algorithm when contracting the graph: edge contraction and star contraction:</p>
            <ol>
              <li><b>Edge contraction</b>: Edge contraction involves finding the min edge incident to each vertex (in the first iteration) and each component thereafter. We then add these edges to our MST and perform the necessary contractions in the contraction stage. This utilizes the light-end property as was discussed above</li>
              <li><b>Star contraction</b>: Star contraction involves flipping a coin for each vertex/ component and finding the heads and tails. This is necessary in star contraction, so we contract into the head and so that we can determine what are the star centers and star satellites. Particularly, we make 0 mean you are a satellite (false) and 1 mean you are a star center (true).</li>
            </ol>
            <p>Here are some <b>implementation details</b>: Our algorithm takes in a graph structure as input and prints out the edges of the MST</p>
            <p><b>Key data structures:</b></p>
            <ul>
              <li><b>Union find data structure</b>: Our union find is based on having a struct which holds information about the parent and rank of each node. This allows us to store information about which component each node belongs to in order to determine which edges are valid edges to contract.</li>
              <li><b>Graph representation</b>: We model the undirected graph with an underlying representation of a directed graph (so a directed edge is listed in the graph twice for the two directions). We based our representation off of the representation used in assignment 3. (Please see the Approach section for more information on how we decided on our graph representation).
              </li>
            </ul>
            <p><b>Key operations:</b></p>
            <ul>
              <li>Find parent and union (read a paper which used compare and swap and that worked pretty well and allowed us to not have to lock up an entire section in order to call these functions)</li>
              <li>We didn’t use the rank attribute for the parallel version of Bor&#367vka’s because that would require an atomic increment which we thought would result in some slowness</li>
            </ul>
            <p><b>Excessive computation and dependency challenges:</b></p>
            <ul>
              <li>The algorithm is broken down into two main components: finding minimum edges out of each component and contracting the graph, each of which posed its own challenges throughout the process of parallelizing</li>
              <li>Finding min edges could be computationally expensive based on what axis of parallelism is necessary, especially since we were using the same graph on every iteration rather than actually creating a new contracted graph. We found that we were doing extra work here and had to change our approach as we explain in the next section</li>
              <li>The contraction stage also had dependencies based on the union-find operations that were done on both endpoints of the edge being contracted. This introduced a critical region that we had to fix. Our approach to account for this is also explained in the next section</li>
            </ul>
            <p><b>Other challenges:</b></p>
            <ul>
              <li>Creating graphs (explained in the Approach section)</li>
              <li>Writing a lock-free union data structure, so that we could decrease the granularity of our locking and critical sections</li>
            </ul>
          </div>
        </div>
      </div>
    </div>

    <div class="container">
      <div class="section">
        <div class="row">
          <div class="col s12 m12">
            <h4>Approach</h4>
            <p><b>Technologies:</b></p>
            <ul>
              <li>We used the GHC machines and C++ for this project. We also used some Python for graph creation and correctness checks. In order parallelize our implementation on the CPU we used OpenMP primitives.</li>
            </ul>

            <table style="width:50%">
                <tr>
                    <td><b>Property</b></td>
                    <td><b>Spec Detail on GHC 26</b></td>
                </tr>
                <tr>
                    <td><b>Architecture:</b></td>
                    <td>x86_64</td>
                </tr>
                <tr>
                    <td><b>Thread(s) per core:</b></td>
                    <td>2</td>
                </tr>
                <tr>
                    <td><b>Core(s) per socket:</b></td>
                    <td>6</td>
                </tr>
                <tr>
                    <td><b>Socket(s):</b></td>
                    <td>1</td>
                </tr>
            </table>

            <p><b>Graph Representation:</b></p>
            <p><b>Initial idea:</b> We determined that we wanted some kind of adjacency list because an adjacency matrix for high vertex counts would be space inefficient (to add to the space, we also needed weights so we would not be able to just use a boolean matrix). Because we need weights on the edges, we started by creating an Edge struct type that held a source, destination, and weight and then made an adjacency list such that each node had a linked list of all its edges. As we started working with this idea and implemented a sequential version of Bor&#367uvka’s with it, we realized that the linked list would not parallelize well and it would also require a lot of overhead in ensuring correctness if we continued with it for the parallel version.</p>
            <p><b>Final idea:</b> We modeled the undirected graph with an underlying representation of a directed graph (so a directed edge is listed in the graph twice for the two directions). We based our representation off of the representation used in assignment 3. Vertices were numbered from 0 to n-1 where n is the number of vertices. We used three arrays, one for offsets, one for destination vertices, and one for weights. The offsets array allowed us to index into the destinations and weights arrays (offset[i] gave us where vertex i’s out-edges started).</p>
            <p>Note: The final graph representation, although easy to visualize, does not lend itself well to updating the graph itself. In 15-210 when we implemented Bor&#367vka’s algorithm we could easily create a new graph by simply creating new vertex and edge sets every time we contracted the graph. Because of the calculation of offsets which would require sorting (and also require roughly twice the graphs size in space as we essentially make a copy of the graph), we decided we would keep the original graph and always operate on the original graph. We used a union-find data structure to handle the task of finding the component a vertex belonged to. The inability to update the graph as it contracts was a source of challenges as we will mention in the description of our many attempts at optimizations as detailed below.</p>
            <p><b>Graph Creation:</b></p>
            <p>We had wanted to use large graphs created on SNAP, but after working with this and the assignment 3 code, we realized the undirectedness and weights of our graph made translation from assignment 3’s conversion code to our representation difficult. Because of that, we decided on creating our own graphs using pseudorandomness for generating edges and weights. Because our graph representation required sorting edges by source node in order to figure out offsets and C++ is not the easiest language to use for such a purpose, we determined our graph structure and values with Python, did all the necessary edge generation and sorting, wrote it out to a text file, and had C++ create the actual graphs using the file information.</p>
            <p>For initial testing we made small graphs of about 20 to 30 nodes and 100 to 1000 edges. Because of the pseudorandomness there was no guarantee that the graphs would be connected, so we had to update our code to handle cases of disconnected graphs. Once we had the sequential version working (we tested sequential correctness by hand for smaller graphs), we used it as a correctness checker for our parallel versions. For correctness checking we removed the randomness for edge weights to ensure all edges had distinct weights (because there is guaranteed to be one correct MST if all edges are distinct). The validation program for checking correctness was also written in Python.</p>
            <p><b>Sequential Implementation:</b></p>
            <p>The sequential version does the following:</p>
              <ol>
                <li>Looks through all the edges</li>
                <li>Finds the representative vertices of the source and destination (if they are in the same component - i.e. have the same representative vertex - then we move onto the next edge because this one has already been contracted. Otherwise save it as that component’s minimum weight edge if it is the lightest edge seen so far)
                <li>Once that is complete for all components, use edge contraction to contract the selected edges</li>
              </ol>
            <p>This process continues until either the number of components is 1 (this is the case for a connected graph), or until the number of components does not change after an iteration (we know the number of components must decrease by at least one while there are edges to contract)</p>
            <p><b>Parallel Implementations:</b></p>
            <p><b>Initial attempt:</b> We started by taking the sequential version as it was written and adding parallel for loops. This introduced the need for two critical regions. The first critical region was in the finding minimum edges phase because we had to find the minimum weighted edge which is hard when there are multiple threads reading and writing to the same min address (we needed to implement something like CAS in order to be consistent). The second critical region came in the contraction phase. Because our loop condition relied on the number of remaining components which would have to be decremented after every edge was contracted and the inserts in the mst_edges array relied on incrementing an index variable which needed to be modified by only one thread at a time.</p>
            <p>Note: Although the following 2 versions did not yield any speedup (they actually performed much worse than our baseline sequential version), working through all the attempts helped us learn more about the structure of Bor&#367vka’s algorithm and important concepts which ultimately helped us pinpoint smaller issues that helped with later parallel versions</p>
            <p>TODO</p>
            <p><b>Find Minimum Edges by Component with Edge Contraction:</b> To get rid of the first critical region, we tried to parallelize over the vertices. Essentially we wanted to have each vertex that was a representative vertex check all the other vertices for those in the same component. If a vertex was found to be in the same component,  they would then iterate through the edges belonging to that vertex looking for the minimum edge. The critical region was not needed in this case because we actually parallelize over the component. We started testing this on a 5000 node graph with 943,000 edges, but it was slower than the sequential.</p>
            <p><b>Find Minimum Edges by Component with Star Contraction:</b> Although this implementation ended up being faster than the edge contraction version on the 5000 node graph, it was still too slow. We created a 1,000,000 node graph with 9,000,000 edges and this version could not complete even after running for over 2 minutes. We determined that trying to mimic the idea of parallelizing finding min_edges over components was not the best idea as we were doing too much unnecessary work. We were essentially doing O(n^2) work by having each representative vertex look through all the vertices. A simple example of where this is bad would be in the first iteration, when every node is it’s own representative vertex. It should only have to look at it’s own edges and be done, but instead it has to loop through all 999999 other nodes and call find_parallel on them to make sure they’re not in the same component.</p>
            <p><b>Find Minimum Edges by Edge with Edge Contraction:</b> Having been unsuccessful with our finding minimum edges by vertex idea, we went back to our first parallel version taken from the baseline sequential code with the original two critical sections. We realized that fine-grained locks would help solve our problem. That way instead of locking the entire min_edges array we could just lock by component. We kept everything else the same This yielded much better results. Running on 16 threads on GHC, we saw that the sequential version took roughly 10 seconds while this parallel version took 2.5 seconds.</p>
            <p><b>Find Minimum Edges by Edge with Star Contraction:</b> We wanted to further speed up the “Find Minimum Edges by Edge with Edge Contraction” version, by parallelizing the contraction using star contraction. The initial attempt at this actually slowed down significantly. We think this is due to the overhead of spawning threads, scheduling them, and then possibly having to execute more iterations of the while loop since star contraction is not guaranteed to contract all the edges at once (from an asymptotic analysis perspective, the math works out so that the edges number of edges left to be contracted decreases by a constant factor, but the actual performance on the machine may be worse).</p>
            <p><b>Threads and Chunk Size Choices:</b></p>
          </div>
        </div>
      </div>
    </div>

    <div class="container">
      <div class="section">
        <div class="row">
          <div class="col s12 m12">
            <h4>Results</h4>
              <img src="images/edge-graph.png" alt="Edge Graph" style="width:450px;height:330px;" class="center-block"/>
              <img src="images/star-graph.png" alt="Star Graph" style="width:450px;height:330px;" class="center-block"> 
          </div>
        </div>
      </div>
    </div>

    <div class="container">
      <div class="section">
        <div class="row">
          <div class="col s12 m12">
            <h4>References</h4>
            <ul>
              <li><a href="https://drive.google.com/file/d/0B4z2gzEmkDDCTUhKUWxJQnR0bEk/view">15-210’s notes</a></li>
              <li>15-418 Assignment 3</li>
              <li><a href="http://dl.acm.org/citation.cfm?id=103458">Paper for lock-free union find</a></li>
            </ul>
          </div>
        </div>
      </div>
    </div>

    <div class="container">
      <div class="section">
        <div class="row">
          <div class="col s12 m12">
            <h4>List of Work By each Student</h4>
            <p>Equal work was performed by both project members.</p>
          </div>
        </div>
      </div>
    </div>

  </main>

  <footer class="page-footer  indigo darken-3">
    <div class="container">
      <div class="row">
        <div class="col l6 s12">
          <h5 class="white-text">15-418 Final Project</h5>
          <p class="grey-text text-lighten-4">by Kathleen Fuh and Shreya Vemuri</p>
          <a href="https://github.com/kfuh1/15418-project.git" target="_blank">GitHub Repository</a>

        </div>
      </div>
    </div>
    <div class="footer-copyright">
      <div class="container">
      Made by <a class="indigo-text text-accent-1" href="http://materializecss.com">Materialize</a>
      </div>
    </div>
  </footer>


  <!--  Scripts-->
  <script src="https://code.jquery.com/jquery-2.1.1.min.js"></script>
  <script src="js/materialize.js"></script>
  <script src="js/init.js"></script>

  </body>
</html>
